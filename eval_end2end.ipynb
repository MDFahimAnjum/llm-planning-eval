{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate.utils import set_seed\n",
    "from tqdm import tqdm\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "from utils.functions import set_seed_all, set_result_filename, run_end2end, check_nltk_resource\n",
    "import os\n",
    "\n",
    "from evaluators.llm_evaluator import LLMEvaluator, LLMLoraEvaluator\n",
    "from generators.llm_generator import LLMGenerator, LLMLoraGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_names =[\n",
    "    \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\",\n",
    "    \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\n",
    "    \"stabilityai/stable-code-3b\",\n",
    "    \"deepseek-ai/deepseek-coder-1.3b-base\"\n",
    "]\n",
    "\n",
    "\n",
    "# generate lora model names\n",
    "lora_model_names = []\n",
    "for m in llm_names:\n",
    "   lora_model_names.append( m.split(\"/\")[1]+\"_spider\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluator_name: stabilityai/stable-code-3b\n",
      "model_savename: stable-code-3b_spider\n"
     ]
    }
   ],
   "source": [
    "seed = 42\n",
    "\n",
    "# evaluator\n",
    "model_indx = 2 # choose the model to evaluate\n",
    "evaluator_name = llm_names[model_indx] #base model name\n",
    "model_savename = lora_model_names[model_indx] #lora model save name\n",
    "evaluation_config = \"evaluation_configs/pro.json\"\n",
    "\n",
    "# generator\n",
    "model_indx = 2 # choose the model to generate\n",
    "generator_name = llm_names[model_indx] #base model name\n",
    "generator_lora_savename = lora_model_names[model_indx] #lora model save name\n",
    "generation_config = \"generation_configs/temp_sampling.json\" # there are two configs for generation: temp_sampling.json (5 candidates) and greedy.json (1 candidate)\n",
    "\n",
    "# populate other parameters\n",
    "print(f\"evaluator_name: {evaluator_name}\")\n",
    "print(f\"model_savename: {model_savename}\")\n",
    "current_directory = os.getcwd() #parameters\n",
    "model_savedatapath = os.path.join(current_directory,f\"checkpts/{model_savename}/model\")\n",
    "evaluator_peft_dir = model_savedatapath\n",
    "\n",
    "\n",
    "test_fname = \"data/spider_dev_400.json\"\n",
    "dataset_name = \"spider\"\n",
    "db_path =\"spider/database\"\n",
    "method_name = \"rerank\" # planning method\n",
    "# result_fname: where the results will be saved for evaluation\n",
    "result_fname = f\"results/{set_result_filename(evaluator_name, generator_name, dataset_name, method_name)}_pro_e2e\" + \".sql\"\n",
    "log_name = f\"log/{set_result_filename(evaluator_name, generator_name, dataset_name, method_name)}_pro_e2e\" + \".json\"\n",
    "\n",
    "retriever_gen = None # retriever generator\n",
    "retriever_eval = None # retriever evaluator\n",
    "\n",
    "\"\"\"\n",
    "yes_token_indx: \n",
    "    the index of the token in the vocabulary that corresponds to the \"Yes\" text.\n",
    "    CodeLlama-Instruct: \"No\" 1939 \"Yes\" 3869\n",
    "    TinyLlama: \"Yes\" 3869\n",
    "\"\"\"\n",
    "yes_token_indx=None#3869"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed\n",
    "set_seed_all(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Evaluator LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18dfed676ba445a1be8f99cec839ec6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes token index: 4374\n"
     ]
    }
   ],
   "source": [
    "evaluator = LLMEvaluator(evaluator_name, db_path, device=\"cuda\",yes_token_indx=yes_token_indx)\n",
    "#evaluator = LLMLoraEvaluator(evaluator_name, evaluator_peft_dir, db_path, device=\"cuda\",yes_token_indx=yes_token_indx)\n",
    "\n",
    "yindx=evaluator.get_yes_token()\n",
    "print(f\"Yes token index: {yindx}\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Generator LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5c06cd3511f4731b2c15b00678b5583",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Some parameters are on the meta device device because they were offloaded to the cpu.\n"
     ]
    }
   ],
   "source": [
    "generator = LLMGenerator(generator_name, device=\"cuda\")\n",
    "#generator = LLMLoraGenerator(generator_name, generator_peft_dir, device=\"cuda\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Planning method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if method_name == \"rerank\":\n",
    "    from planning_methods.llm_planner import rerank as planner\n",
    "else:\n",
    "    raise ValueError(f\"Unknown planning method: {method_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "End2end run and store results for evalulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [27:25<00:00, 548.67s/it]\n"
     ]
    }
   ],
   "source": [
    "run_end2end(generator, evaluator,generation_config, \\\n",
    "            evaluation_config, planner, retriever_gen, retriever_eval, \\\n",
    "                test_fname,dataset_name,result_fname,log_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: 'punkt_tab' exists in the NLTK data directory.\n"
     ]
    }
   ],
   "source": [
    "check_nltk_resource()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "easy pred: SELECT DISTINCT s.country   FROM singer AS s   JOIN singer_in_concert AS sic   ON s.singer_id = sic.singer_id   JOIN concert AS c   ON sic.concert_id = c.concert_id   WHERE s.age > 20   GROUP BY s.country;\n",
      "easy gold: SELECT DISTINCT country FROM singer WHERE age > 20;\n",
      "\n",
      "easy pred: SELECT DISTINCT course_name FROM courses ;\n",
      "easy gold: SELECT DISTINCT t1.course_name FROM courses AS t1 JOIN student_enrolment_courses AS t2 ON t1.course_id = t2.course_id;\n",
      "\n",
      "easy pred: SELECT COUNT(DISTINCT winner_name) FROM matches ;\n",
      "easy gold: SELECT COUNT(DISTINCT loser_name) FROM matches;\n",
      "\n",
      "                     easy                 medium               hard                 extra                all                 \n",
      "count                3                    0                    0                    0                    3                   \n",
      "=====================   EXECUTION ACCURACY     =====================\n",
      "execution            0.333                0.000                0.000                0.000                0.333               \n",
      "\n",
      "====================== EXACT MATCHING ACCURACY =====================\n",
      "exact match          0.000                0.000                0.000                0.000                0.000               \n",
      "\n",
      "---------------------PARTIAL MATCHING ACCURACY----------------------\n",
      "select               0.667                0.000                0.000                0.000                0.667               \n",
      "select(no AGG)       0.667                0.000                0.000                0.000                0.667               \n",
      "where                1.000                0.000                0.000                0.000                1.000               \n",
      "where(no OP)         1.000                0.000                0.000                0.000                1.000               \n",
      "group(no Having)     0.000                0.000                0.000                0.000                0.000               \n",
      "group                0.000                0.000                0.000                0.000                0.000               \n",
      "order                0.000                0.000                0.000                0.000                0.000               \n",
      "and/or               1.000                0.000                0.000                0.000                1.000               \n",
      "IUEN                 0.000                0.000                0.000                0.000                0.000               \n",
      "keywords             0.000                0.000                0.000                0.000                0.000               \n",
      "---------------------- PARTIAL MATCHING RECALL ----------------------\n",
      "select               0.667                0.000                0.000                0.000                0.667               \n",
      "select(no AGG)       0.667                0.000                0.000                0.000                0.667               \n",
      "where                1.000                0.000                0.000                0.000                1.000               \n",
      "where(no OP)         1.000                0.000                0.000                0.000                1.000               \n",
      "group(no Having)     0.000                0.000                0.000                0.000                0.000               \n",
      "group                0.000                0.000                0.000                0.000                0.000               \n",
      "order                0.000                0.000                0.000                0.000                0.000               \n",
      "and/or               1.000                0.000                0.000                0.000                1.000               \n",
      "IUEN                 0.000                0.000                0.000                0.000                0.000               \n",
      "keywords             0.000                0.000                0.000                0.000                0.000               \n",
      "---------------------- PARTIAL MATCHING F1 --------------------------\n",
      "select               0.667                0.000                0.000                0.000                0.667               \n",
      "select(no AGG)       0.667                0.000                0.000                0.000                0.667               \n",
      "where                1.000                0.000                0.000                0.000                1.000               \n",
      "where(no OP)         1.000                0.000                0.000                0.000                1.000               \n",
      "group(no Having)     1.000                0.000                0.000                0.000                1.000               \n",
      "group                1.000                0.000                0.000                0.000                1.000               \n",
      "order                1.000                0.000                0.000                0.000                1.000               \n",
      "and/or               1.000                0.000                0.000                0.000                1.000               \n",
      "IUEN                 1.000                0.000                0.000                0.000                1.000               \n",
      "keywords             1.000                0.000                0.000                0.000                1.000               \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "db = db_path # the directory that contains all the databases and test suites\n",
    "table = \"spider/tables.json\" # the tables.json schema file\n",
    "pred = result_fname # the path to the predicted queries\n",
    "gold = \"data/spider_dev_400_gold.sql\" # the path to the gold queries\n",
    "etype = \"all\" # evaluation type, exec for test suite accuracy, match for the original exact set match accuracy\n",
    "pscript = \"test-suite-sql-eval/evaluation.py\" # the evaluation script\n",
    "\n",
    "cmd = [\n",
    "    \"python\", \"-u\", pscript,\n",
    "    \"--gold\", gold,\n",
    "    \"--pred\", pred,\n",
    "    \"--db\", db,\n",
    "    \"--table\", table,\n",
    "    \"--etype\", etype\n",
    "]\n",
    "\n",
    "result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "print(result.stdout)\n",
    "print(result.stderr)  # Check for errors\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "r1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
