{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate.utils import set_seed\n",
    "from tqdm import tqdm\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "from utils.functions import set_seed_all, set_result_filename, run_end2end, check_nltk_resource, swap_memory\n",
    "import os\n",
    "\n",
    "from evaluators.llm_evaluator import LLMEvaluator, LLMLoraEvaluator\n",
    "from generators.llm_generator import LLMGenerator, LLMLoraGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_names =[\n",
    "    \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\", # generation\n",
    "    \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\n",
    "    \"stabilityai/stable-code-3b\", # generation\n",
    "    \"deepseek-ai/deepseek-coder-1.3b-base\",\n",
    "    \"deepseek-ai/deepseek-coder-1.3b-instruct\" # generation\n",
    "]\n",
    "\n",
    "\n",
    "# generate lora model names\n",
    "lora_model_names = []\n",
    "for m in llm_names:\n",
    "   lora_model_names.append( m.split(\"/\")[1]+\"_spider\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluator_name: TinyLlama/TinyLlama-1.1B-Chat-v1.0\n",
      "evaluator_lora: TinyLlama-1.1B-Chat-v1.0_spider\n",
      "generator_name: TinyLlama/TinyLlama-1.1B-Chat-v1.0\n",
      "generator_lora: TinyLlama-1.1B-Chat-v1.0_spider\n"
     ]
    }
   ],
   "source": [
    "seed = 42\n",
    "device_swap = True # swap between cuda and cpu to save vram\n",
    "\n",
    "# evaluator\n",
    "model_indx = 0 # choose the model to evaluate\n",
    "evaluator_name = llm_names[model_indx] #base model name\n",
    "model_savename = lora_model_names[model_indx] #lora model save name\n",
    "evaluation_config = \"evaluation_configs/pro.json\"\n",
    "print(f\"evaluator_name: {evaluator_name}\")\n",
    "print(f\"evaluator_lora: {model_savename}\")\n",
    "\n",
    "# generator\n",
    "model_indx = 0 # choose the model to generate\n",
    "generator_name = llm_names[model_indx] #base model name\n",
    "generator_lora_savename = lora_model_names[model_indx] #lora model save name\n",
    "print(f\"generator_name: {generator_name}\")\n",
    "print(f\"generator_lora: {generator_lora_savename}\")\n",
    "\n",
    "prompt_method = 2 # 0 for tinyllama\n",
    "\n",
    "# populate other parameters\n",
    "current_directory = os.getcwd() #parameters\n",
    "model_savedatapath = os.path.join(current_directory,f\"checkpts/{model_savename}/model\")\n",
    "evaluator_peft_dir = model_savedatapath\n",
    "\n",
    "\n",
    "test_fname = \"data/spider_dev_400.json\"\n",
    "dataset_name = \"spider\"\n",
    "db_path =\"spider/database\"\n",
    "method_name = \"rerank\" # planning method: greedy, rerank, iterative\n",
    "# result_fname: where the results will be saved for evaluation\n",
    "result_fname = f\"results/{set_result_filename(evaluator_name, generator_name, dataset_name, method_name)}_pro_e2e\" + \".sql\"\n",
    "log_name = f\"log/{set_result_filename(evaluator_name, generator_name, dataset_name, method_name)}_pro_e2e\" + \".json\"\n",
    "\n",
    "retriever_gen = None # retriever generator\n",
    "retriever_eval = None # retriever evaluator\n",
    "\n",
    "\"\"\"\n",
    "yes_token_indx: \n",
    "    the index of the token in the vocabulary that corresponds to the \"Yes\" text.\n",
    "    CodeLlama-Instruct: \"No\" 1939 \"Yes\" 3869\n",
    "    TinyLlama: \"Yes\" 3869\n",
    "\"\"\"\n",
    "yes_token_indx=None#3869"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed\n",
    "set_seed_all(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Evaluator LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model on cpu\n",
      "Yes token index: 3869\n"
     ]
    }
   ],
   "source": [
    "#evaluator = LLMEvaluator(evaluator_name, db_path, device=\"cuda\",yes_token_indx=yes_token_indx)\n",
    "evaluator = LLMLoraEvaluator(evaluator_name, evaluator_peft_dir, db_path, device=\"cuda\",yes_token_indx=yes_token_indx)\n",
    "\n",
    "# move model to cpu for now\n",
    "if device_swap:\n",
    "    swap_memory(evaluator.model, device=\"cpu\",verbose=True)\n",
    "\n",
    "yindx=evaluator.get_yes_token()\n",
    "print(f\"Yes token index: {yindx}\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Generator LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model on cpu\n"
     ]
    }
   ],
   "source": [
    "generator = LLMGenerator(generator_name, device=\"cuda\")\n",
    "#generator = LLMLoraGenerator(generator_name, generator_peft_dir, device=\"cuda\")\n",
    "\n",
    "# move model to cpu for now\n",
    "if device_swap:\n",
    "    swap_memory(generator.model, device=\"cpu\",verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Planning method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM planner: rerank\n"
     ]
    }
   ],
   "source": [
    "if method_name == \"rerank\":\n",
    "    from planning_methods.llm_planner import rerank as planner\n",
    "    generation_config = \"generation_configs/temp_sampling.json\" # there are two configs for generation: temp_sampling.json (5 candidates) and greedy.json (1 candidate)\n",
    "elif method_name == \"greedy\":\n",
    "    from planning_methods.llm_planner import greedy as planner\n",
    "    generation_config = \"generation_configs/greedy.json\"\n",
    "elif method_name == \"iterative\":\n",
    "    from planning_methods.llm_planner import iter_correction as planner\n",
    "    generation_config = \"generation_configs/temp_sampling.json\"\n",
    "else:\n",
    "    raise ValueError(f\"Unknown planning method: {method_name}\")\n",
    "print(f\"LLM planner: {method_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "End2end run and store results for evalulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "limit = 10 # we will only run the first 10 examples for testing\n",
    "run_end2end(generator, evaluator,generation_config, \\\n",
    "            evaluation_config, planner, retriever_gen, retriever_eval, \\\n",
    "                test_fname,dataset_name,result_fname,log_name,device_swap,prompt_method,limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: 'punkt_tab' exists in the NLTK data directory.\n"
     ]
    }
   ],
   "source": [
    "check_nltk_resource()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "easy pred: SELECT DISTINCT country   FROM singer   WHERE singer.age > 20   AND singer.is_male = 1   ORDER BY country;\n",
      "easy gold: SELECT DISTINCT country FROM singer WHERE age > 20;\n",
      "\n",
      "easy pred: SELECT DISTINCT course_name   FROM courses   WHERE EXISTS (SELECT *   FROM student_enrolment   JOIN student_course ON student_course.course_id = courses.course_id   JOIN transcript_contents ON transcript_contents.transcript_id = student_enrolment.transcript_id   JOIN transcript_contents ON transcript_contents.transcript_id = transcript_contents.transcript_id   JOIN transcript_contents ON transcript_contents.transcript_id = transcript_contents.transcript_id   JOIN transcript_contents ON transcript_contents.transcript_id = transcript_contents.transcript_id   JOIN student_course ON student_course.course_id = transcript_contents.course_id   JOIN departments ON departments.department_id = student_enrolment.department_id   JOIN courses ON courses.course_id = student_enrolment.course_id   JOIN departments ON departments.department_id = student_enrolment.department_id   JOIN courses ON courses.course_id = student_enrolment.course_id   JOIN departments ON departments.department_id = student_enrolment.department_id   JOIN courses ON courses.course_id =;\n",
      "easy gold: SELECT DISTINCT t1.course_name FROM courses AS t1 JOIN student_enrolment_courses AS t2 ON t1.course_id = t2.course_id;\n",
      "\n",
      "easy pred: SELECT COUNT(DISTINCT loser_name) AS num_distinct_name   FROM matches   WHERE loser_rank = 3   ORDER BY loser_rank DESC;\n",
      "easy gold: SELECT COUNT(DISTINCT loser_name) FROM matches;\n",
      "\n",
      "easy pred: SELECT SUM(CASE WHEN caused_by_ship_id = id THEN 1 ELSE 0 END)   FROM death   WHERE killed = 1   AND injured = 1   GROUP BY killed, injured;\n",
      "easy gold: SELECT AVG(injured) FROM death;\n",
      "\n",
      "easy pred: SELECT singer.name,   (SELECT MAX(sales) FROM song WHERE singer_id = singer.singer_id) AS highest_sales,   singer.net_worth_millions   FROM singer   ORDER BY highest_sales DESC;\n",
      "easy gold: SELECT name FROM singer ORDER BY net_worth_millions ASC;\n",
      "\n",
      "easy pred: SELECT dog_id   FROM dogs   WHERE (date_of_birth = (SELECT MAX(date_of_birth) FROM dogs));\n",
      "easy gold: SELECT MAX(age) FROM dogs;\n",
      "\n",
      "easy pred: SELECT COUNT(*)   FROM cars_data   WHERE mpg > 4 ;\n",
      "easy gold: SELECT COUNT(*) FROM cars_data WHERE cylinders > 4;\n",
      "\n",
      "easy pred: SELECT COUNT(*) AS 'Number of poker players'   FROM poker_player ;\n",
      "easy gold: SELECT COUNT(*) FROM poker_player;\n",
      "\n",
      "easy pred: SELECT *   FROM templates   WHERE template_type_code IN ('A', 'B')   AND (  -- find documents with between one and two paragraphs  (SELECT COUNT(*)   FROM documents   WHERE template_id IN (SELECT template_id   FROM templates   WHERE template_type_code IN ('A', 'B')   AND version_number BETWEEN 1 AND 2)   AND document_id NOT IN (SELECT document_id   FROM documents   WHERE template_id IN (SELECT template_id   FROM templates   WHERE template_type_code IN ('A', 'B')   AND version_number BETWEEN 1 AND 2)))   OR (SELECT COUNT(*)   FROM documents   WHERE template_id IN (SELECT template_id   FROM templates   WHERE template_type_code IN ('C')   AND version_number BETWEEN 1 AND 2)   AND document_id NOT IN (SELECT document_id   FROM documents   WHERE template_id IN (SELECT template_id   FROM templates   WHERE template_type_code IN ('A', 'B')   AND version_number BETWEEN 1 AND 2)));\n",
      "easy gold: SELECT document_id FROM paragraphs GROUP BY document_id HAVING COUNT(*) BETWEEN 1 AND 2;\n",
      "\n",
      "easy pred: SELECT AVG(age) AS avg_age   FROM visit   WHERE level_of_membership <> 4;\n",
      "easy gold: SELECT AVG(age) FROM visitor WHERE level_of_membership <= 4;\n",
      "\n",
      "                     easy                 medium               hard                 extra                all                 \n",
      "count                10                   0                    0                    0                    10                  \n",
      "=====================   EXECUTION ACCURACY     =====================\n",
      "execution            0.100                0.000                0.000                0.000                0.100               \n",
      "\n",
      "====================== EXACT MATCHING ACCURACY =====================\n",
      "exact match          0.000                0.000                0.000                0.000                0.000               \n",
      "\n",
      "---------------------PARTIAL MATCHING ACCURACY----------------------\n",
      "select               1.000                0.000                0.000                0.000                1.000               \n",
      "select(no AGG)       1.000                0.000                0.000                0.000                1.000               \n",
      "where                0.000                0.000                0.000                0.000                0.000               \n",
      "where(no OP)         0.000                0.000                0.000                0.000                0.000               \n",
      "group(no Having)     0.000                0.000                0.000                0.000                0.000               \n",
      "group                0.000                0.000                0.000                0.000                0.000               \n",
      "order                0.000                0.000                0.000                0.000                0.000               \n",
      "and/or               1.000                0.000                0.000                0.000                1.000               \n",
      "IUEN                 0.000                0.000                0.000                0.000                0.000               \n",
      "keywords             0.500                0.000                0.000                0.000                0.500               \n",
      "---------------------- PARTIAL MATCHING RECALL ----------------------\n",
      "select               0.200                0.000                0.000                0.000                0.200               \n",
      "select(no AGG)       0.200                0.000                0.000                0.000                0.200               \n",
      "where                0.000                0.000                0.000                0.000                0.000               \n",
      "where(no OP)         0.000                0.000                0.000                0.000                0.000               \n",
      "group(no Having)     0.000                0.000                0.000                0.000                0.000               \n",
      "group                0.000                0.000                0.000                0.000                0.000               \n",
      "order                0.000                0.000                0.000                0.000                0.000               \n",
      "and/or               0.900                0.000                0.000                0.000                0.900               \n",
      "IUEN                 0.000                0.000                0.000                0.000                0.000               \n",
      "keywords             0.200                0.000                0.000                0.000                0.200               \n",
      "---------------------- PARTIAL MATCHING F1 --------------------------\n",
      "select               0.333                0.000                0.000                0.000                0.333               \n",
      "select(no AGG)       0.333                0.000                0.000                0.000                0.333               \n",
      "where                1.000                0.000                0.000                0.000                1.000               \n",
      "where(no OP)         1.000                0.000                0.000                0.000                1.000               \n",
      "group(no Having)     1.000                0.000                0.000                0.000                1.000               \n",
      "group                1.000                0.000                0.000                0.000                1.000               \n",
      "order                1.000                0.000                0.000                0.000                1.000               \n",
      "and/or               0.947                0.000                0.000                0.000                0.947               \n",
      "IUEN                 1.000                0.000                0.000                0.000                1.000               \n",
      "keywords             0.286                0.000                0.000                0.000                0.286               \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "db = db_path # the directory that contains all the databases and test suites\n",
    "table = \"spider/tables.json\" # the tables.json schema file\n",
    "pred = result_fname # the path to the predicted queries\n",
    "gold = \"data/spider_dev_400_gold.sql\" # the path to the gold queries\n",
    "etype = \"all\" # evaluation type, exec for test suite accuracy, match for the original exact set match accuracy\n",
    "pscript = \"test-suite-sql-eval/evaluation.py\" # the evaluation script\n",
    "\n",
    "cmd = [\n",
    "    \"python\", \"-u\", pscript,\n",
    "    \"--gold\", gold,\n",
    "    \"--pred\", pred,\n",
    "    \"--db\", db,\n",
    "    \"--table\", table,\n",
    "    \"--etype\", etype\n",
    "]\n",
    "\n",
    "result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "print(result.stdout)\n",
    "print(result.stderr)  # Check for errors\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "r1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
